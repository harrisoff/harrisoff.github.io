---
layout: post
title: "WebGL 笔记"
date: 2020-03-27 22:01:00
categories: 笔记 javascript
---

[MDN - 常量](https://developer.mozilla.org/zh-CN/docs/Web/API/WebGL_API/Constants)   
[WebGL Fundamentals 中文](https://webglfundamentals.org/webgl/lessons/zh_cn/)   
[WebGL fundamentals 中文 - 设置和安装](https://webglfundamentals.org/webgl/lessons/zh_cn/webgl-setup-and-installation.html)

[在线 demo](/webgl.html)

## 前言

### 参考链接

- [webgl fundamental](https://webglfundamentals.org/webgl/lessons/zh_cn/)
- [OpenGL ES Shading Language 2.0 参考笔记](https://blog.csdn.net/tkokof1/article/details/79066371)

### ESSL

JS 不能操作 GPU，需要 ESSL 作为过渡。

OpenGL ES Shading Language，aka ESSL，着色器使用的语言，基于 OpenGL Shading Language，aka GLSL。

> 也有说 GLSL 是 Graphic Library Shader Language 的

### space 空间

- clipspace 裁剪空间，范围 [-1, 1]
- colorspace 颜色空间，范围 [0, 1]

webgl 中的坐标数据使用的是 clipspace。

JS 可以直接提供这个区间内的数据，也可以提供 canvas 的坐标数据，然后在 ESSL 中添加一步处理操作，生成 clipspace 坐标数据。

> 大致流程是：
> 1. canvas 坐标除以 canvas 的宽高，映射到 [0, 1]
> 2. 乘 2，映射到 [0, 2]
> 3. 减 1，得到 [-1, 1]

webgl 坐标系原点在左下，canvas 坐标系原点在左上。

> 可以通过 ESSL 的矩阵运算翻转 y 轴来统一原点位置。

## shader 着色器

JS 中使用 webgl API 创建 shader，通过 shader 为 ESSL 中的数据赋值，最后由 ESSL 操作 GPU 进行绘制。

webgl 的整个流程概括一下就是：
1. 创建着色器
2. 通过着色器为数据赋值
3. 调用 `gl.drawArrays()` 或 `gl.drawElements()` 结束 JS 部分
4. 运行 ESSL 代码开始绘制

> `gl.drawArrays()` 和 `gl.drawElements()` 的区别是，后者可以复用顶点数据

下面是一个除了数据赋值部分的绘制流程。

```js
// ===== canvas 初始化 =====
const canvas = document.getElementById('canvas');
const gl = canvas.getContext('webgl');
// ===== shader 初始化 =====
// shader src code
const vertexShaderSrc = ''; // vertex shader ESSL 源码
const fragmentShaderSrc = ''; // fragment shader ESSL 源码
// vertex shader
const vertexShader = gl.createShader(gl.VERTEX_SHADER); // 创建 shader
gl.shaderSource(vertexShader, vertexShaderSrc);// 绑定源码
gl.compileShader(vertexShader);// 编译
// fragment shader
const fragmentShader = gl.createShader(gl.FRAGMENT_SHADER); // 创建 shader
gl.shaderSource(fragmentShader, fragmentShaderSrc);// 绑定源码
gl.compileShader(fragmentShader);// 编译
// ===== program 初始化 =====
const shaderProgram = gl.createProgram(); // 创建 program
gl.attachShader(shaderProgram, vertexShader); // 添加 vertex shader
gl.attachShader(shaderProgram, fragmentShader); // 添加 fragment shader
gl.linkProgram(shaderProgram); // 链接
gl.useProgram(shaderProgram); // 使用
// ===== 赋值 =====
// attribute/uniform/texture
// ===== 绘制 =====
const primitiveType = gl.TRIANGLES; // 图像的形状
const drawOffset = 0; // 偏移
const count = bufferData.length / size; // 执行次数
gl.drawArrays(primitiveType, drawOffset, count);
```

## ESSL

### 类型 type

分为标量和矢量，暂时用到了以下几个。

- vec[234]，向量
- mat[234]，矩阵
- sampler2D，纹理，范围 [0, 1]
- bool，布尔值

#### 1. vec

`vec4` 表示长度为 4 的数据，有 4 种索引：
- `{ x, y, z, w }`
- `{ s, t, p, q }`
- `{ r, g, b, a }`
- `{ 0, 1, 2, 3 }`

比如对于 `vec4 v`，`v.x`/`v.s`/`v.r`/`v[0]` 的意义是一样的。

可以进行矢量计算，比如：

```c#
// 例 1
vec4 a = vec4(1, 2, 3, 4);
vec4 b = a * 2.0; // b 是 vec4(2, 4, 6, 8);
// 例 2
attribute vec4 a_position; // 长度 4
uniform vec2 u_resolution; // 长度 2
void main() {
  // 对 a_position 的前两项进行计算
  vec2 zeroToOne = a_position.xy / u_resolution;
  // ...
}
```

有类似于 JS 解构赋值的语法：

```c#
vec4 v;
// 例 1
v.yyyy /* 等价于 */ vec4(v.y, v.y, v.y, v.y)
// 例 2
vec4(v.rgb, 1) /* 等价于 */ vec4(v.r, v.g, v.b, 1)
// 例 3
vec4(1) /* 等价于 */ vec4(1, 1, 1, 1)
```

快捷交换分量位置：
```c#
vec4 color; // 正常顺序为 rgba
gl_FragColor = color.bgra; // 交换了 r 和 b 的位置
```

ESSL 是强类型的：

```c#
float f = 1; // 错误
vec2(1, 1); // vec2() 对类型做了转换，所以不报错
```

#### 2. mat

#### 3. sampler2D

#### 4. bool

### 限定符 qualifier

- attribute，只能用于 vertex shader，从 JS buffer 中获取数据
- uniform，用于保存 ESSL 执行期间使用到的不变的量
- varying，可变量，是一种 vertex 给 fragment 传值的方式

#### attribute 属性

属性只能用于 vertex shader。

shader 中通常有多个 attribute，比如点的坐标和颜色两个，对应地，JS 中也要定义多个 buffer，每个 buffer 的赋值都是互不影响的，都有以下几步。

```js
// 1. 准备数据
const bufferData = [ /* ... */ ]; // 待添加的数据
const buffer = gl.createBuffer(); // 创建 buffer
gl.bindBuffer(gl.ARRAY_BUFFER, buffer); // 绑定到 gl.ARRAY_BUFFER 点
gl.bufferData(
  gl.ARRAY_BUFFER,
  new Float32Array(bufferData),
  gl.STATIC_DRAW,
); // 添加 buffer 数据
// 2. 获取 attribute 地址
const positionLocation = gl.getAttribLocation(program, 'a_position');
gl.enableVertexAttribArray(positionLocation); // 启用该 attribute
// 3. 设置该 attribute 赋值时的参数
const size = 2; // 每次读取的长度
const type = gl.FLOAT; // 每个单位的数据类型，还有 gl.UNSIGNED_BYTE 等
const normalize = false; // 转换为浮点数时，是否把数值映射到指定区间，比如 [-1, 1] 和 [0, 1]
const stride = 0; // TODO:
const offset = 0; // 偏移值
gl.vertexAttribPointer(positionLocation, size, type, normalize, stride, offset);
```

数据可以是 32 位浮点数据或 8 位无符号整型数据，对应 JS 的 `Float32Array` 和 `Uint8Array`。

```js
[
  [1, 2, 3],
  [4, 5, 6],
  [7, 8, 9]
]

[
  1, 2, 3,
  4, 5, 6,
  7, 8, 9
]
```

#### uniform 全局变量

默认值为 0。

赋值 API：`gl.uniform[1234][fi][v]()`。需要根据变量类型决定，见 [MDN](https://developer.mozilla.org/zh-CN/docs/Web/API/WebGLRenderingContext/uniform)

#### varying 可变量

分别在两个 shader 中定义同名的 varying 变量，就可以通过这个变量传递数据。

其他几种都只能在声明的同时赋值，不能先声明再赋值：

```c#
attribute vec2 a_color;
uniform vec2 u_color;
varying vec2 v_color;

u_color = a_color; // 错，can't modify a uniform "u_color"
v_color = a_color; // 正确
```

JS -> vertex shader -> fragment shader

## 2D 变换

2D 变换就是在图形的原始坐标数据上进行**四则运算**，有四种：
- 平移
- 旋转
- 缩放
- 矩阵

- **不要**在 JS 中直接修改原始数据
- **尽量**提供变换的数据给 ESSL，在 ESSL 中操作原始数据

2D 变换操作的顺序会影响结果。图形旋转不会导致坐标轴方向变化，比如旋转之后拉伸，还是水平和竖直方向上发生拉伸。

### 平移 & 旋转 & 缩放

假设有以下变量：
- `u_translation`，平移数据
- `u_rotation`，旋转数据
- `u_scale`，缩放数据

那么应用了以上三种变换的 vertex shader 会像这样：

```c#
attribute vec2 a_position; // 原始数据
uniform vec2 u_translation;
uniform vec2 u_rotation;
uniform vec2 u_scale;
// 1. 缩放
vec2 scaledPosition = a_position * u_scale;
// 2. 旋转
vec2 rotatedPosition = vec2(
  scaledPosition.x * u_rotation.y + scaledPosition.y * u_rotation.x,
  scaledPosition.y * u_rotation.y - scaledPosition.x * u_rotation.x
);
// 3. 平移
vec2 position = rotatedPosition + u_translation;
```

### 矩阵

**重要提示：如果发现效果与预期不同，极有可能是矩阵的顺序错了。**


每种变换都可以写成一个矩阵，把三个矩阵相乘，就得到了最终的矩阵，最后把这个矩阵传递给 vertex shader 进行运算。

好处是什么呢？看一下上面分着的写法，如果现在要添加或者取消一种变换，需要修改 vertex shader 的代码。如果使用矩阵：

- 添加变换时，只需要新定义一个然后多一步乘法
- 取消变换时，只需要删掉对应的乘法

并且最终只生成一个矩阵，vertex shader 的代码更简洁。

前面的 canvas 转 clipspace 坐标系的几行代码，实际上就可以写成一个矩阵。示例代码就不贴了，见 [webgl fundamentals](https://webglfundamentals.org/webgl/lessons/zh_cn/webgl-2d-matrices.html)

实际上，基本没有什么场景是只有单个变换的，因此矩阵是非常重要的，到后面三维变换的部分也是一样。

这里可以封装一些函数，返回常用矩阵，比如：
- 单位矩阵
- 平移矩阵
- 旋转矩阵
- 缩放矩阵
- canvas 转 clipspace

```js
// 1. 修改原点
let matrix = translate(matrix, -50, -75);
// 2. 再执行二维操作，顺序是有影响的
matrix = translate(matrix, translateX, translateY);
matrix = rotate(matrix, angle);
matrix = scale(matrix, zoomX, zoomY);
// 3. 转换坐标系
matrix = projection(gl.canvas.width, gl.canvas.height);
```

#### 矩阵的顺序/乘法交换律

矩阵在一定条件下才满足乘法交换律，见[百度知道](https://zhidao.baidu.com/question/110424802)。

多个操作单独执行和封装为矩阵并没有什么两样，还是需要有先后顺序的。

### framebuffer 帧缓冲

当需要连续添加多个纹理时，需要保存每一次处理后的纹理，在这个纹理上继续进行下一次处理，即：原始纹理 -> 纹理 1 -> 纹理 2 -> ... -> 最终纹理 n。这时需要帧缓冲。

一般的纹理渲染是绘制到了屏幕上，而帧缓冲渲染是把纹理绘制到了 framebuffer 中，没有任何显示，等到所有纹理处理完成后再把最终结果显示到屏幕上。

只需要准备两对 texture/framebuffer，每次处理都把另一对的旧值覆盖掉即可。

关键步骤

```js
const framebufferObject = gl.createFramebuffer();
// 渲染到 framebuffer
gl.bindFramebuffer(gl.FRAMEBUFFER, framebufferObject);
// 退出 framebuffer，渲染到屏幕
gl.bindFramebuffer(gl.FRAMEBUFFER, null);
```

## 3D 变换

对于一个三角形，如果它在一个二维平面上，是只有一个面的，即朝向我们的这一面。但是到了三维空间，它就得分前面和后面了。

三角形是由三个顶点绘制的，webgl 规定，当这三个顶点的绘制顺序：

- 为顺时针时，看到的面为反面
- 为逆时针时，看到的面为正面

### 几个 API

- `gl.enable(gl.CULL_FACE)`
   如上面所说，一个平面图形是有正反两个面的。如果只需要其中一面，可以开启这个属性，只绘制正面，不绘制反面
- `gl.enable(gl.DEPTH_TEST)`
   没有开启这个属性的时候，空间里的每一个点都没有记录其“深度”，即该点到观察者的距离，导致虽然有些部分本应该被遮挡，但是实际上仍然渲染出来了。

## texture 纹理

首先说一下原理。

绘制实际上就是为 `gl_FragColor` 赋值，比如固定值时就是纯色。而纹理中 `gl_FragColor` 的值是**图片上对应的点的颜色**。

类型为 sampler2D。

纹理的设置有三步：
1. 提供图片的缩放数据
2. 提供图片数据
3. 使用前两项数据，在 fragment shader 中调用 `texture2D()`

```js
// 1. 设置图片的缩放数据
const textureLocation = gl.getAttribLocation(program, 'a_texture'); // a_texture 范围 [0, 1]
const buffer = gl.createBuffer();
gl.bindBuffer(gl.ARRAY_BUFFER, buffer);
gl.bufferData(
  gl.ARRAY_BUFFER,
  new Float32Array([
    // 填满整个矩形（范围 [0, 1]
    0.0, 0.0,
    1.0, 0.0,
    0.0, 1.0,
    0.0, 1.0,
    1.0, 0.0,
    1.0, 1.0,
  ]),
  gl.STATIC_DRAW,
);
gl.enableVertexAttribArray(textureLocation);
// 2. 准备图片
const image = await getImage(); // 等待 image 的 onload 事件
// 3. texture 初始化
const texture = gl.createTexture(); // 创建
gl.bindTexture(gl.TEXTURE_2D, texture); // 绑定
// 4. 设置是否重复绘制、缩放时的算法等参数
gl.texParameteri(/* 一些参数 */);
// 5. 添加图片到纹理
gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, gl.RGBA, gl.UNSIGNED_BYTE, image);
```

然后在 fragment shader 中

```c#
precision mediump float;
// u_image 变量没有在 JS 中用到，只是一个形参
uniform sampler2D u_image;
varying vec2 v_texcoord; // 就是 a_texcoord
void main() {
  // 从图片上寻找每个点的颜色
  gl_FragColor = texture2D(u_image, v_texcoord).rgba;
}
```

### 拉伸和缩小

有时候，需要添加纹理的面和实际使用的图片的尺寸是不一样大的。因此需要说明每个面上的顶点和其纹理图片上的顶点的对应关系，这就是 vertex shader 中 `a_texcoord` 属性的作用了。

`a_texcoord` 用来说明图片是怎样贴到面上去的。

用正方形的面和图片举几个栗子：

```js
// 把整张图片按比例缩小，贴到面上
[
  0, 0,
  0, 1,
  1, 0,
  1, 0,
  0, 1,
  1, 1
]
// 把图片左上 1/4 的区域贴到面上
[
  0,   0,
  0,   0.5,
  0.5, 0,
  0.5, 0,
  0,   0.5,
  0.5, 0.5
]
// 超过 1 的部分会重复绘制结束点的像素
[
  0, 0,
  0, 2,
  2, 0,
  2, 0,
  0, 2,
  2, 2
]
```

图片的大小和实际绘制大小不同的时候就有一个问题了，变形之后的像素怎么计算？比如一个 32x32 的图片缩小到 2x2，或者 2x2 放大到 32x32。

首先，这里需要 `gl.texParameteri(gl.TEXTURE_2D, pname, param)` 方法。

这时 `pname` 有以下两个值：
- gl.TEXTURE_MIN_FILTER，图片缩小时
- gl.TEXTURE_MAG_FILTER，图片放大时

`param` 有以下 6 个取值，分别对应不同算法，除了效果，还有性能方面的差异：
- gl.NEAREST
- gl.LINEAR
- gl.NEAREST_MIPMAP_NEAREST
- gl.LINEAR_MIPMAP_NEAREST
- gl.NEAREST_MIPMAP_LINEAR
- gl.LINEAR_MIPMAP_LINEAR

放大时只可以取前 2 个值；缩小时才有全部 6 种取值，但后 4 种需要搭配 `gl.generateMipmap(gl.TEXTURE_2D)` 才可以使用，并且这时并不需要显式设置 `gl.texParameteri(gl.TEXTURE_2D)` 。

反正推荐使用 `gl.texParameteri(gl.TEXTURE_2D)`。

### 重复绘制

超过 1 时默认会根据比例重复绘制图片，可以通过 `gl.texParameteri()` 设置某个方向上不重复绘制：

```js
gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S/gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE)
```

> s,t,u,v 对应 x,y,z,w

不重复绘制整张图，会重复图片边缘部分的像素。

### 2 的整数次幂

webgl 要求图片的尺寸必须是 2 的整数次幂，对于非整数次幂的图片，需要这样处理：

```js
gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);
gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR);
```

> 也没研究为啥，反正这么做就是了。

综合起来，代码会像是这样：

```js
// 是 2 的幂
if (isPowerOf2(image.width) && isPowerOf2(image.height)) {
  gl.generateMipmap(gl.TEXTURE_2D);
}
// 不是 2 的幂
else {
  gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
  gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);
  gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR);
}
```

### 多面多纹理

好几个面要使用不同的纹理，最佳实践就是把所有图片合成为一张大图，作为一个纹理，然后引用每张图片在整张大图上的坐标位置。这种方法叫做**纹理图集**。

> 像极了 CSS 的雪碧图

游戏里就是这么做的。

> 妈妈我会写游戏啦！（不是

当然，这一张大图是提前做好的，不是 JS 现场拼接的。

### 纹理的方向

以正方体的一个面为例。

纯色的时候是看不出什么方向的，换成纹理就能知道图片贴上去之后是正的、倒的还是斜的了。

面是由三角形拼接成的，而每个三角形是由三个顶点按顺序绘制得到的。所以对于一个正方形，共有 4x2x2=16 种绘制方式。考虑到空间中的面是有前后两个方向的，如果仅绘制前面，即逆时针的顺序绘制顶点，有 8 种方式。

纹理是对于一个平面来说的，所以只需要提供两个坐标点。   
对于三维空间，画面的时候是需要提供三个坐标点的，但是在这个面上，这些三维的坐标点实际上可以转换为二维的。比如正方体的正面是平行于 XY 坐标轴所在的面的，Z 坐标全部为 0，相当于只有 X 和 Y 坐标。

想要得到*正*的纹理，需要**面的顶点的绘制顺序**和**纹理的顶点的绘制顺序**相同。

## 其他

### canvas

一个 `<canvas />` 元素有两种尺寸：
- canvas 内部的像素数
- 显示在屏幕上的像素数

下面是一个在屏幕上显示为 800x600 的画布，但是其内部实际的像素数量为 400x300。

```html
<canvas width="400" height="300" style="width:800px; height:600px"></canvas>
```

上面是宽高刚好为整数倍的情况，如果不是整数倍，就会出现比例失调。可以通过 `canvas.height = canvas.clientHeight` 使得内外像素数一致。
